{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2) (6000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>받다,홀리데이,구매하다,개인적,케이스,디자인,아쉽다,립스틱,색깔,예쁘다</td>\n",
       "      <td>디자인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>좋다,가격,구매,잘하다,같다</td>\n",
       "      <td>가격</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>전,이니,노세범,쓰다,퍼프,작다,불편하다,퍼프,적당하다,용량,많다,케이스,고급,지다...</td>\n",
       "      <td>용량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>색깔,예쁘다,맘,들다</td>\n",
       "      <td>디자인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>화,신청,하다,신정,끼다,토요일,오전,받다,생각,늦다,디자인,맘,들다,처음,바르다,...</td>\n",
       "      <td>디자인</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x    y\n",
       "0            받다,홀리데이,구매하다,개인적,케이스,디자인,아쉽다,립스틱,색깔,예쁘다  디자인\n",
       "1                                    좋다,가격,구매,잘하다,같다   가격\n",
       "2  전,이니,노세범,쓰다,퍼프,작다,불편하다,퍼프,적당하다,용량,많다,케이스,고급,지다...   용량\n",
       "3                                        색깔,예쁘다,맘,들다  디자인\n",
       "4  화,신청,하다,신정,끼다,토요일,오전,받다,생각,늦다,디자인,맘,들다,처음,바르다,...  디자인"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "for words in train['x']:\n",
    "    a = []\n",
    "    a.append(words)\n",
    "    train_corpus.append(a)\n",
    "    \n",
    "test_corpus = []\n",
    "for words in test['x']:\n",
    "    a = []\n",
    "    a.append(words)\n",
    "    test_corpus.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['받다,홀리데이,구매하다,개인적,케이스,디자인,아쉽다,립스틱,색깔,예쁘다'], ['좋다,가격,구매,잘하다,같다']]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token_review = []\n",
    "for corpus in train_corpus:\n",
    "    c = corpus[0].split(\",\")\n",
    "    train_token_review.append(c)\n",
    "        \n",
    "test_token_review = []\n",
    "for corpus in test_corpus:\n",
    "    c = corpus[0].split(\",\")\n",
    "    test_token_review.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['받다', '홀리데이', '구매하다', '개인적', '케이스', '디자인', '아쉽다', '립스틱', '색깔', '예쁘다'],\n",
       " ['좋다', '가격', '구매', '잘하다', '같다']]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_review[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "tagged_train_docs = [TaggedDocument(d, c) for d, c in zip(train_token_review, train['y'].values)]\n",
    "tagged_test_docs = [TaggedDocument(d, c) for d, c in zip(test_token_review, test['y'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['받다', '홀리데이', '구매하다', '개인적', '케이스', '디자인', '아쉽다', '립스틱', '색깔', '예쁘다'], tags='디자인'),\n",
       " TaggedDocument(words=['좋다', '가격', '구매', '잘하다', '같다'], tags='가격')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_train_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['은은하다', '고급스럽다', '좋다', '색', '자연스럽다', '고급', '지다', '싸다', '잘산거', '같다', '쓰다', '마켓', '아이폰', '앱', '작성'], tags='디자인'),\n",
       " TaggedDocument(words=['제품', '받다', '색상', '예쁘다', '다르다', '사람', '사다', '반품', '하다', '보내다', '반품하다', '팔수', '이다', '그렇다', '제품', '확인하다', '보내다', '하다', '아니다', '색상', '손가락', '테스트하다', '제품', '인터넷', '물건', '사다', '정도', '확인', '하다', '보내다'], tags='색상')]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_test_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = Doc2Vec(dm=0,\n",
    "                         min_count=3,\n",
    "                         vector_size=256, \n",
    "                         window=5,\n",
    "                         negative=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.5/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 112.86632919311523\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = train_model.alpha # fix the learning rate, no decay\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y_train = [doc.tags for doc in tagged_train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "y_test = [doc.tags for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.asarray(y_train, dtype=str)\n",
    "y_test_np = np.asarray(y_test, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 256)\n",
      "(6000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_np.shape)\n",
    "print(X_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000,)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_np.shape)\n",
    "print(y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['디자인', '색상', '감촉', ..., '향기', '용량', '색상'], dtype='<U3')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = list(set(y_test_np))\n",
    "target_mapping_table = {}\n",
    "for idx, names in enumerate(target_names):\n",
    "    target_mapping_table[names] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가격': 3, '감촉': 5, '디자인': 4, '색상': 0, '용량': 1, '향기': 2}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mapping_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['디자인', '가격', '용량', ..., '용량', '디자인', '가격'], dtype='<U3')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_np)\n",
    "print(y_test_np)\n",
    "print(y_train_pred)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = fnn_clf.predict(X_train_np)\n",
    "test_prediction = fnn_clf.predict(X_test_np)\n",
    "\n",
    "train_y_pred = []\n",
    "for i in range(len(train_prediction)):\n",
    "    train_y_pred.append(np.argmax(train_prediction[i]))\n",
    "\n",
    "test_y_pred = []\n",
    "for i in range(len(test_prediction)):\n",
    "    test_y_pred.append(np.argmax(test_prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "tr_y_pred = le.inverse_transform(train_y_pred)\n",
    "te_y_pred = le.inverse_transform(test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['디자인', '가격', '용량', ..., '용량', '향기', '색상'], dtype='<U3')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_label = le.fit_transform(y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, ..., 4, 2, 0])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "b = le.inverse_transform(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000,)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(confusion_matrix(tr_y_pred, b),\n",
    "                            index=target_names,\n",
    "                            columns=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>색상</th>\n",
       "      <th>용량</th>\n",
       "      <th>향기</th>\n",
       "      <th>가격</th>\n",
       "      <th>디자인</th>\n",
       "      <th>감촉</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>색상</th>\n",
       "      <td>3009</td>\n",
       "      <td>389</td>\n",
       "      <td>284</td>\n",
       "      <td>226</td>\n",
       "      <td>222</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>용량</th>\n",
       "      <td>268</td>\n",
       "      <td>2573</td>\n",
       "      <td>159</td>\n",
       "      <td>339</td>\n",
       "      <td>164</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>향기</th>\n",
       "      <td>160</td>\n",
       "      <td>88</td>\n",
       "      <td>2543</td>\n",
       "      <td>468</td>\n",
       "      <td>57</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>가격</th>\n",
       "      <td>181</td>\n",
       "      <td>348</td>\n",
       "      <td>685</td>\n",
       "      <td>2649</td>\n",
       "      <td>123</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>디자인</th>\n",
       "      <td>210</td>\n",
       "      <td>169</td>\n",
       "      <td>89</td>\n",
       "      <td>138</td>\n",
       "      <td>3297</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>감촉</th>\n",
       "      <td>172</td>\n",
       "      <td>433</td>\n",
       "      <td>240</td>\n",
       "      <td>180</td>\n",
       "      <td>137</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       색상    용량    향기    가격   디자인    감촉\n",
       "색상   3009   389   284   226   222   264\n",
       "용량    268  2573   159   339   164   422\n",
       "향기    160    88  2543   468    57   177\n",
       "가격    181   348   685  2649   123   179\n",
       "디자인   210   169    89   138  3297   163\n",
       "감촉    172   433   240   180   137  2795"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "24000\n",
      "['색상', '용량', '향기', '가격', '디자인', '감촉']\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(train_y_pred))\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fnn_clf = tf.keras.Sequential()\n",
    "fnn_clf.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(len(X_train[0]), )))\n",
    "fnn_clf.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "fnn_clf.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "fnn_clf.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f088446f5c0>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 50,182\n",
      "Trainable params: 50,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fnn_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['디자인', '가격', '용량', ..., '용량', '디자인', '가격'], dtype='<U3')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples\n",
      "Epoch 1/10\n",
      "24000/24000 [==============================] - 0s 19us/sample - loss: 1.7628 - sparse_categorical_accuracy: 0.3195\n",
      "Epoch 2/10\n",
      "24000/24000 [==============================] - 0s 7us/sample - loss: 1.6337 - sparse_categorical_accuracy: 0.4707\n",
      "Epoch 3/10\n",
      "24000/24000 [==============================] - 0s 5us/sample - loss: 1.4098 - sparse_categorical_accuracy: 0.5734\n",
      "Epoch 4/10\n",
      "24000/24000 [==============================] - 0s 5us/sample - loss: 1.2232 - sparse_categorical_accuracy: 0.6158\n",
      "Epoch 5/10\n",
      "24000/24000 [==============================] - 0s 5us/sample - loss: 1.0965 - sparse_categorical_accuracy: 0.6443\n",
      "Epoch 6/10\n",
      "24000/24000 [==============================] - 0s 5us/sample - loss: 1.0212 - sparse_categorical_accuracy: 0.6550\n",
      "Epoch 7/10\n",
      "24000/24000 [==============================] - 0s 6us/sample - loss: 0.9688 - sparse_categorical_accuracy: 0.6741\n",
      "Epoch 8/10\n",
      "24000/24000 [==============================] - 0s 7us/sample - loss: 0.9338 - sparse_categorical_accuracy: 0.6799\n",
      "Epoch 9/10\n",
      "24000/24000 [==============================] - 0s 6us/sample - loss: 0.9098 - sparse_categorical_accuracy: 0.6848\n",
      "Epoch 10/10\n",
      "24000/24000 [==============================] - 0s 5us/sample - loss: 0.8811 - sparse_categorical_accuracy: 0.6962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0820501da0>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn_clf.fit(X_train_np, y_label, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "fnn_clf.save('C:/Users/daumsoft/PycharmProjects/visualization/model/fnn_model.h5')\n",
    "\n",
    "train_prediction = fnn_clf.predict(X_train)\n",
    "test_prediction = fnn_clf.predict(X_test)\n",
    "\n",
    "train_y_pred = []\n",
    "for i in range(len(train_prediction)):\n",
    "    train_y_pred.append(np.argmax(train_prediction[i]))\n",
    "\n",
    "test_y_pred = []\n",
    "for i in range(len(test_prediction)):\n",
    "    test_y_pred.append(np.argmax(test_prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
